# 摘要

MapReduce 及其变体在商品集群上实现大规模数据密集型应用程序方面非常成功。然而，这些系统中的大多数建立在不适合于其他流行应用的非循环数据流模型。本文针对一类这样的应用程序：那些在多个并行操作中重用一组工作数据的应用程序。这包括许多迭代机器学习算法，以及交互式数据分析工具。我们提出了一个名为 Spark 的新框架，支持这些应用程序，同时保留 MapReduce 的可扩展性和容错性。为了实现这些目标，Spark 引入了一个称为弹性分布式数据集（RDDs）的抽象。 RDD是跨一组机器分区的对象的只读集合，如果分区丢失，可以重新构建。 Spark 在迭代机器学习作业中的性能优于 Hadoop 10倍，并且可用于以亚秒级响应时间交互式查询 39GB 数据集。

# 1.前言

集群计算的新模型已经变得广泛流行，其中通过自动提供位置感知调度，容错和负载平衡的系统在不可靠机器的集群上执行数据并行计算。 MapReduce开创了这个模型，而像 Dryad 和 Map-Reduce-Merge 这样的系统推广了支持的数据流类型。这些系统通过提供编程模型来实现其可扩展性和容错性，其中用户创建非循环数据流图以通过一组运算符传递输入数据。这允许底层系统管理调度和对故障做出反应，而无需用户干预。虽然该数据流编程模型对于大类应用程序是有用的，但是存在不能作为非循环数据流有效地表示的应用。在本文中，我们专注于一类这样的应用程序：那些在多个并行操作中重用一组工作数据的应用程序。这包括两个用例，我们已经看到 Hadoop 用户报告 MapReduce 不足：

* **Iterative jobs（迭代的任务）**：许多常见机器学习算法对同一数据集重复应用函数以优化参数（例如，通过梯度计算）。虽然每个迭代可以表示为 MapReduce / Dryad 作业，但每个作业必须从磁盘重新加载数据，从而产生显着的性能。
* **Interactive analytics（交互式分析）**：Hadoop 通常用于通过 SQL 接口（如 Pig 和 Hive ）对大型数据集运行 ad-hoc 探索性查询。理想情况下，用户将能够在多个机器上将感兴趣的数据集加载到内存中并重复查询。但是，使用 Hadoop，每个查询都会产生显着的延迟（几十秒），因为它作为一个单独的 MapReduce 作业运行，并从磁盘读取数据。本文提出了一个新的集群计算框架，称为 Spark，它支持应用程序与工作集，同时提供类似 MapReduce 的可扩展性和容错属性。

Spark 中的主要抽象是一个弹性分布数据集（RDD），它代表在一组机器上分区的对象的只读集合，如果分区丢失，可以重新构建这些对象。用户可以在内存中跨机器显式缓存 RDD，并在多个类似 MapReduce 的并行操作中重用它。 RDD 通过谱系概念实现容错：如果 RDD 的分区丢失，RDD 具有足够的信息，关于它是如何从其他 RDD 派生的，以便能够仅重建该分区。尽管 RDD 不是一般的共享内存抽象，但它们一方面表现在表达性之间，另一方面表示可扩展性和可靠性，我们发现它们非常适合各种应用。

Spark 在 Scala 中实现，它是 Java VM 的静态类型的高级编程语言，并且公开了一个类似于 DryadLINQ 的功能编程接口。此外，Spark 可以从 Scala 解释器的修改版本中主动使用，这允许用户定义 RDDs，函数，变量和类，并在集群上的并行操作中使用它们。我们相信 Spark是第一个允许高效的通用编程语言以交互方式处理集群上的大型数据集的系统。

虽然我们的 Spark实现仍然是一个原型，早期的系统经验是令人鼓舞的。我们表明Spark可以在机器学习工作负载中超过 Hadoop 10倍，并且可以交互使用以亚秒级延迟扫描 39GB 的数据集。

本文组织如下。第2节描述了 Spark 的编程模型和 RDD。第3节显示了一些示例作业。第4节描述了我们的实现，包括我们与 Scala及其解释器的集成。第5节提出早期结果。我们在第6节调查相关工作，最后在第7节讨论。



