# 摘要

MapReduce 及其变体在商品集群上实现大规模数据密集型应用程序方面非常成功。然而，这些系统中的大多数建立在不适合于其他流行应用的非循环数据流模型。本文针对一类这样的应用程序：那些在多个并行操作中重用一组工作数据的应用程序。这包括许多迭代机器学习算法，以及交互式数据分析工具。我们提出了一个名为 Spark 的新框架，支持这些应用程序，同时保留 MapReduce 的可扩展性和容错性。为了实现这些目标，Spark 引入了一个称为弹性分布式数据集（RDDs）的抽象。 RDD是跨一组机器分区的对象的只读集合，如果分区丢失，可以重新构建。 Spark 在迭代机器学习作业中的性能优于 Hadoop 10倍，并且可用于以亚秒级响应时间交互式查询 39GB 数据集。

# 1. 前言

集群计算的新模型已经变得广泛流行，其中通过自动提供位置感知调度，容错和负载平衡的系统在不可靠机器的集群上执行数据并行计算。 MapReduce开创了这个模型，而像 Dryad 和 Map-Reduce-Merge 这样的系统推广了支持的数据流类型。这些系统通过提供编程模型来实现其可扩展性和容错性，其中用户创建非循环数据流图以通过一组运算符传递输入数据。这允许底层系统管理调度和对故障做出反应，而无需用户干预。虽然该数据流编程模型对于大类应用程序是有用的，但是存在不能作为非循环数据流有效地表示的应用。在本文中，我们专注于一类这样的应用程序：那些在多个并行操作中重用一组工作数据的应用程序。这包括两个用例，我们已经看到 Hadoop 用户报告 MapReduce 不足：

* **Iterative jobs（迭代的任务）**：许多常见机器学习算法对同一数据集重复应用函数以优化参数（例如，通过梯度计算）。虽然每个迭代可以表示为 MapReduce / Dryad 作业，但每个作业必须从磁盘重新加载数据，从而产生显着的性能。
* **Interactive analytics（交互式分析）**：Hadoop 通常用于通过 SQL 接口（如 Pig 和 Hive ）对大型数据集运行 ad-hoc 探索性查询。理想情况下，用户将能够在多个机器上将感兴趣的数据集加载到内存中并重复查询。但是，使用 Hadoop，每个查询都会产生显着的延迟（几十秒），因为它作为一个单独的 MapReduce 作业运行，并从磁盘读取数据。本文提出了一个新的集群计算框架，称为 Spark，它支持应用程序与工作集，同时提供类似 MapReduce 的可扩展性和容错属性。

Spark 中的主要抽象是一个弹性分布数据集（RDD），它代表在一组机器上分区的对象的只读集合，如果分区丢失，可以重新构建这些对象。用户可以在内存中跨机器显式缓存 RDD，并在多个类似 MapReduce 的并行操作中重用它。 RDD 通过谱系概念实现容错：如果 RDD 的分区丢失，RDD 具有足够的信息，关于它是如何从其他 RDD 派生的，以便能够仅重建该分区。尽管 RDD 不是一般的共享内存抽象，但它们一方面表现在表达性之间，另一方面表示可扩展性和可靠性，我们发现它们非常适合各种应用。

Spark 在 Scala 中实现，它是 Java VM 的静态类型的高级编程语言，并且公开了一个类似于 DryadLINQ 的功能编程接口。此外，Spark 可以从 Scala 解释器的修改版本中主动使用，这允许用户定义 RDDs，函数，变量和类，并在集群上的并行操作中使用它们。我们相信 Spark是第一个允许高效的通用编程语言以交互方式处理集群上的大型数据集的系统。

虽然我们的 Spark实现仍然是一个原型，早期的系统经验是令人鼓舞的。我们表明Spark可以在机器学习工作负载中超过 Hadoop 10倍，并且可以交互使用以亚秒级延迟扫描 39GB 的数据集。

本文组织如下。第2节描述了 Spark 的编程模型和 RDD。第3节显示了一些示例作业。第4节描述了我们的实现，包括我们与 Scala及其解释器的集成。第5节提出早期结果。我们在第6节调查相关工作，最后在第7节讨论。

# 2. 编程模型

要使用 Spark，开发人员编写一个驱动程序，实现其应用程序的高级控制流程，并并行启动各种操作。 Spark 为并行编程提供了两个主要的抽象：弹性分布式数据集和对这些数据集的并行操作（通过传递一个函数应用于数据集来调用）。此外，Spark 支持两种限制类型的共享变量，这些变量可以在集群上运行的函数中使用，我们将在后面解释。

### 2.1 Resilient Distributed Datasets \(RDDs\)

弹性分布式数据集（RDD）是跨一组机器分区的对象的只读集合，如果分区丢失，可以重新构建这些对象。 RDD 的元素不需要存在于物理存储中;相反，RDD 的句柄包含足够的信息来计算从可靠存储中的数据开始的 RDD。这意味着如果节点失败，RDD 总是可以重建。

在 Spark 中，每个 RDD 由一个 Scala 对象表示。 Spark 让程序员以四种方式构造 RDD：

* 从共享文件系统中的文件，如 Hadoop 分布式文件系统（HDFS）。

* 通过在驱动程序中“并行化” Scala 集合（例如，数组），这意味着将其划分为将被发送到多个节点的多个片。

* 通过转换现有的 RDD。可以使用称为 flatMap 的操作将具有类型A的元素的数据集转换为具有类型B的元素的数据集，其通过用户提供的类型A⇒列表\[B\]的函数传递每个元素。 其他变换可以使用 flatMap 来表示，包括 map（通过类型A⇒B的函数的 pass 元素）和 filter（匹配谓词的 pick 元素）。

* 通过更改现有 RDD 的持久性。默认情况下，RDD 是懒惰和短暂的。也就是说，当数据集的分区在并行操作中使用（例如，通过 map 函数传递文件的块）时，数据集的分区可以根据需要实现，并在使用后从内存中分离。 但是，用户可以通过两个操作更改 RDD 的持久性：

  * 缓存操作使数据集延迟，但暗示它应该在第一次计算之后保存在内存中，因为它将被重用。

  * 保存操作将评估数据集并将其写入分布式文件系统（如 HDFS）。保存的版本用于将来的操作。

我们注意到，我们的缓存操作只是一个提示：如果集群中没有足够的内存来缓存数据集的所有分区，Spark将在使用时重新计算它们。我们选择了这种设计，使得Spark程序在节点故障或数据集太大时仍能继续工作（性能降低）。这个想法是松散地类似于虚拟内存。

我们还计划扩展 Spark 以支持其他级别的持久性（例如，跨多个节点的内存中复制）。我们的目标是让用户在存储 RDD 的成本，访问它的速度，丢失部分的可能性和重新计算它的成本之间进行权衡。

### 2.2 Parallel Operations

可以对 RDD 执行多个并行操作：

* **reduce**：使用相关函数组合数据集元素，以在驱动程序中产生结果。
* **collect**：将数据集的所有元素发送到驱动程序 driver 端。例如，一种并行更新数组的简单方法是并行化，映射和收集数组。
* **foreach**：通过用户提供的函数传递每个元素。这仅仅是为了函数的副作用（可能是将数据复制到另一个系统上，更新到另一个可变的变量）。

我们注意到 Spark 目前不支持 MapReduce 中的分组 reduce 操作; reduce 的结果只在一个进程（驱动程序 drive r端）收集。 如第7节所述，我们计划使用分布式数据集上的“随机”变换支持未来的分组减少。然而，即使使用单个减少器也足以表达各种有用的算法。例如，最近一篇关于多核系统上机器学习 MapReduce 的文章实现了10种不支持并行还原的学习算法。

### 2.3 Shared Variables

程序员通过将闭包（函数）传递给 Spark 来调用 map，filter 和 reduce 等操作。正如在函数式编程中，这些闭包可以引用创建它们的作用域中的变量。通常，当 Spark 在工作节点上运行闭包时，这些变量将复制到工作线程。但是，Spark 还允许程序员创建两种限制类型的共享变量，以支持两种简单但常见的使用模式：

* **Broadcast variables**：如果在多个并行操作中使用大的只读数据（例如，查找表），则优选地将它仅分发给 worker 一次，而不是将其与每个闭包一起包装。 Spark 让程序员创建一个包含该值的“广播变量”对象，并确保它只被复制到每个 worker 一次。
* **Accumulators**：这些 worker 只能“添加”到使用关联操作的变量，并且只有驱动程序可以读取。它们可以用于实现 MapReduce 中的计数器，并为并行和提供更强制的语法。可以为具有 “add” 运算和 “zero” 值的任何类型定义累加器。由于它们的“仅添加”语义，它们更易于容错。

# 3. Examples

我们现在显示一些示例 Spark 程序。注意，我们省略变量类型，因为 Scala 支持类型推断。

### 3.1 Text Search

假设我们希望计算存储在 HDFS 中的大型日志文件中包含错误的行。这可以通过从文件数据集对象开始实现，如下所示：

```scala
    val file = spark.textFile("hdfs://...")

    val errs = file.filter(_.contains("ERROR"))

    val ones = errs.map(_ => 1)

    val count = ones.reduce(_+_)
```

我们首先创建一个名为 file 的分布式数据集，表示 HDFS file as a collection of lines。我们转换此数据集以创建包含 “ERROR”（errs）的行集，然后将每行映射到1，并使用 reduce 将这些行相加。 filter，map 和 reduce 的参数是函数文字的 Scala 语法。

请注意，err 和 ones 是从未实现的延迟 RDD。相反，当调用 reduce 时，每个 worker 节点以流的方式扫描输入块以评估它们，添加这些以执行本地缩减，并将其本地计数发送到驱动器。当以这种方式与懒数据集一起使用时，Spark 会密切地模拟 MapReduce。

Spark 与其他框架不同的地方在于，它可以使一些中间数据集在操作中保持不变。例如，如果想重用 errs 数据集，我们可以从它创建一个缓存的 RDD 如下：

```scala
    val cachedErrs = errs.cache()
```

我们现在将能够像往常一样对 cachedErrs 或从它派生的数据集调用并行操作，但是节点会在第一次计算它们后缓存 cachedErrs 的分区到内存中，从而大大加快了对它的后续操作。

### 3.2 Logistic Regression

以下程序实现逻辑回归，一种迭代分类算法，试图找到最佳分离两组点的超平面 w。该算法执行梯度下降：它以随机值开始 w，并且在每次迭代中，它对数据的 w 的函数求和以在改进它的方向上移动 w。因此，它通过跨越迭代在内存中缓存数据极大地受益。我们不详细解释逻辑回归，但我们使用它来展示一些新的 Spark 特性。

```scala
    // Read points from a text file and cache them

    val points = spark.textFile(...)

    .map(parsePoint).cache()

    // Initialize w to random D-dimensional vector

    var w = Vector.random(D)

    // Run multiple iterations to update w

    for (i <- 1 to ITERATIONS) {

        val grad = spark.accumulator(new Vector(D))

        for (p <- points) { // Runs in parallel

            val s = (1/(1+exp(-p.y * (w dot p.x)))-1) * p.y

            grad += s * p.x
        }
        w -= grad.value
    }
```

首先，虽然我们创建一个 RDD 称为点，我们通过运行一个 for 循环来处理它。 Scala 中的关键字是用于调用集合的 foreach 方法的语法糖，其中循环体作为闭包。也就是说，（p &lt; - points）{body} 的代码等同于 points.foreach（p =&gt;{body}）。因此，我们调用 Spark 的并行 foreach 操作。

第二，为了总结梯度，我们使用一个称为 gradient 的累加器变量（具有类型 V ector 的值）。请注意，循环使用重载的 + = 运算符添加到渐变。累加器和语法的组合允许 Spark 程序看起来很像强制性串行程序。事实上，这个例子不同于只有三行的逻辑回归的串行版本。

### 3.3 Alternating Least Squares

我们的最后一个例子是称为交替最小二乘法（ALS）的算法。 ALS 用于协作过滤问题，诸如基于他们的电影评级历史（如在 Netflix 挑战中）预测用户对未看到的电影的评级。与我们以前的例子不同，ALS 是 CPU 密集型而不是数据密集型。

我们简要描述 ALS，请自行参考官方 ALS 的细节。假设我们想要预测 u 个用户对 m 个电影的评分，并且我们有一个部分填充的矩阵 R 包含一些用户电影对的已知评级。 ALS 将 R 分别作为尺寸为 m×k 和 k×u 的两个矩阵 M 和 U 的乘积;也就是说，每个用户和每个电影具有描述其特征的k维“特征向量”，并且用户对电影的评级是其特征向量和电影的点积。 ALS 使用已知的标准求解 M 和 U，然后计算 M×U 以预测未知的标准。这是使用以下迭代过程完成的：

1.将 M 初始化为随机值。

2.优化 U 给定 M 以最小化 R 上的误差。

3.优化 M 给定 U 以最小化 R 上的误差。

4.重复步骤2和3直到收敛。

可以通过在步骤2和3中更新每个节点上的不同用户/电影来并行化 ALS。然而，由于所有步骤都使用 R，因此使 R 成为广播变量并且不会在每个步骤重新发送到每个节点是有帮助的。 ALS 的 Spark 实现如下所示。 注意我们并行化集合 0 直到 u（Scala范围对象），并收集它来更新每个数组：

```scala
    val Rb = spark.broadcast(R)

    for (i <- 1 to ITERATIONS) {

        U = spark.parallelize(0 until u)

        .map(j => updateUser(j, Rb, M))

        .collect()

        M = spark.parallelize(0 until m)

        .map(j => updateUser(j, Rb, U))

        .collect()

    }
```



