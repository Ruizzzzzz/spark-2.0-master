# Abstract

我们提供弹性分布式数据集（RDDs），分布式内存抽象，允许程序员以容错方式在大型集群上执行内存中计算。 RDD 是由当前计算框架无效处理的两种类型的应用程序激励的：迭代算法和交互式数据挖掘工具。在这两种情况下，将数据保存在内存中可以提高性能一个数量级。为了有效地实现容错，RDD 提供了一种限制形式的共享内存，基于粗粒变换，而不是对共享状态的细粒度更新。然而，我们表明 RDD 足够表达以捕获大量的计算，包括最近的专门的程序设计迭代作业的模型，如 Pregel，以及这些模型没有捕获的新应用程序。我们在一个称为 Spark 的系统中实现了 RDD，我们通过各种用户应用程序和基准来评估。

# 1. Introduction 

集群计算框架如 MapReduce \[10\] 和 Dryad \[19\] 已被广泛应用于大规模数据分析。这些系统允许用户使用一组高级操作符来编写并行计算，而不必担心工作分布和容错。

虽然当前框架提供了访问集群的计算资源的大量抽象，但是它们缺乏利用分布式存储器的抽象。这使得它们对于一类重要的新兴应用程序无效：那些在多个计算中重用中间结果的应用程序。数据重用在许多迭代机器学习和图形算法中是常见的，包括 PageRank，K-means 聚类和逻辑回归。另一个引人注目的用例是交互式数据挖掘，其中用户在数据的相同子集上运行多个自组织查询。不幸的是，在大多数当前框架中，在计算之间（例如，在两个 MapReduce 作业之间）重用数据的唯一方式是将其写入外部稳定存储系统，例如分布式文件系统。这在由于数据复制而导致的大量开销中，磁盘 I / O 和序列化，这可以支配应用程序执行时间。

意识到这个问题，研究人员为需要数据重用的某些应用程序开发了专门的框架。例如，Pregel \[22\] 是一个用于在存储器中保留中间数据的迭代图计算的系统，而 HaLoop \[7\] 提供了一个迭代的 MapReduce 接口。但是，这些框架仅支持特定的计算模式（例如，循环一系列 MapReduce 步骤），并为这些模式隐式执行数据共享。它们不提供用于更一般再使用的抽象，例如，以使用户将若干数据集加载到存储器中并跨它们运行即席查询。

在本文中，我们提出了一种称为弹性分布式数据集（RDDs）的新抽象，可以在广泛的应用程序中有效地重用数据。 RDD 是容错的并行数据结构，它允许用户将中间结果明确地保存在内存中，控制它们的分区以优化数据放置，并使用丰富的运算符操作它们。

设计 RDD 的主要挑战是定义一个可以有效提供容错的编程接口。内存存储群集的现有抽象（如分布式共享内存\[24\]，键值存储\[25\]，数据库和 Piccolo \[27\]）基于对可变状态（例如，表中的单元格）的细粒度更新提供了一个接口。使用此接口，提供容错的唯一方法是跨机器复制数据或跨机器记录更新。这两种方法对于数据密集型工作负载都是昂贵的，因为它们需要复制大量的数据以转移集群的网络，其带宽远低于RAM的带宽，并且它们招致大量的存储开销。

与这些系统相反，RDD 提供基于对许多数据项应用相同操作的粗粒变换（例如，map，filter 和 join）的接口。这允许它们通过记录用于构建数据集（其血统）而不是实际数据的变换来高效地提供容错。如果 RDD 的分区丢失，则 RDD 具有关于如何从其他 RDD 存储仅计算该分区。因此，丢失的数据可以被恢复，通常相当快速，而不需要昂贵的复制。

虽然基于粗粒度变换的接口可能最初看起来有限，但 RDD 对于许多并行应用程序是很好的，因为这些应用程序自然对多个数据项应用相同的操作。实际上，我们表明，RDDs 可以有效地表达许多具有提出分离系统的集群编程模型，包括 MapReduce，DryadLINQ，SQL，Pregel 和 HaLoop，以及这些系统不捕获的新应用程序，如交互式数据挖掘。 RDD 满足计算需求的能力，以前只是通过引入新的框架是我们相信，RDD 抽象的力量的最可靠的证据。

实现了 RDD 系统调用，其用于在加州大学伯克利分校和几家公司的研究和生产应用。 Spark 提供了一种方便的语言集成编程接口，类似于在编程语言\[2\]中的 DryadLINQ \[31\]。此外，Spark 可以交互式地用于从 Scala 解释器查询大数据集。我们相信 Spark 是第一个系统，允许通用编程语言以交互速度用于集群上的内存中数据挖掘。

我们通过微基准和用户应用的测量来评估 RDD 和 Spark。我们显示 Spark 的迭代应用程序的速度比 Hadoop 快20倍，速度supareal世界数据分析报告由40×，并可以积极地使用5-7s延迟扫描1 TB数据集。更基本的是，为了说明RDD的通用性，我们在Spark之上实现了Pregel和HaLoop编程模型，包括它们使用的放置优化，作为相对较小的库（每行200行代码）。

我们通过微基准和用户应用的测量来评估 RDD 和 Spark。我们显示 Spark 对于迭代应用程序的速度比 Hadoop 快20倍，可以将现实世界的数据分析报告加速40倍，并且可以主动使用5-7秒的延迟扫描1 TB 数据集。更基本的是，为了说明 RDD 的通用性，我们在 Spark 之上实现了 Pregel 和 HaLoop 编程模型，包括它们使用的放置优化，作为相对较小的库（每行200行代码）。

本文首先概述了 RDDs（§2）和 Spark（§3）。然后讨论 RDDs 的内部表示（§4），我们的实现（§5）和实验结果（§6）。最后，我们讨论 RDD 如何捕获几个现有的群集编程模型（§7），调查相关工作（§8），并得出结论。

# 2. Resilient Distributed Datasets \(RDDs\) 

本节提供 RDD 的概述。我们首先定义 RDD（§2.1），并在 Spark 中描述程序接口（§2.2）。然后我们比较 RDDs 与自适应共享内存抽象（§2.3）。最后，我们讨论 RDD 模型的限制（§2.4）。

# 2.1 RDD Abstraction 

形式上，RDD 是只读的，分区的记录集合。 RDD 只能通过（1）稳定存储中的数据或（2）其他 RDD 中的确定性操作来创建。这些操作变换将它们与 RDD 上的其他操作区分开来。转换的示例包括map，filter 和 join。

























